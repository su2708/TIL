#TIL #스파르타코딩클럽 [[2411]]

## 1. 팀 프로젝트 중간 집계
### streamlit
- 기본적인 UI 설계 구성 완료
- 사이드바에 선택 사항들 게시
- 사용자의 질문과 챗봇의 답변이 말풍선 형태로 메인 화면에 보이도록 구성
- 대화가 이어지면 이전 말풍선이 위로 올라가며 대화 기록을 계속 보여줌
![[UI 설계 구성.png]]


### FastAPI
- 기본적인 Fast API 구조 설계 완료
- front.py와 server.py로 구분
- front.py
	- 현재는 streamlit UI의 chat_input()이 fast api를 거쳐 잘 화면에 표시되는 지 확인 완료
	- 추후 streamlit part와 협력하여 UI 디자인 완성
```python
# Streamlit UI 구성
st.title("Chat with GPT-4")
st.write("Type your question below and get a response.")

# 사용자 입력
question = st.chat_input("질문을 입력하세요:")

# 질문 입력 시 답변 요청
if question:
    with st.spinner("Waiting for a response..."):
        # FastAPI 서버로 POST 요청
        response = requests.post(API_URL, json={"question": question})
        
        if response.status_code == 200:
            answer = response.json().get("answer", "No answer received.")
            st.write(f"**Answer:** {answer}")
        else:
            st.error("Failed to get a response from the server.")
```

- server.py
	- fast api로 openai 모델을 불러와 응답을 반환 받는 것까지 확인 완료
	- 추후 임베딩한 파일과 함께 RAG 모델을 연결할 예정
```python
# OpenAI 초기화
client = OpenAI(
    api_key=OPENAI_API_KEY,
)

# FastAPI 앱 초기화
app = FastAPI()

# 요청 모델 정의
class QueryRequest(BaseModel):
    question: str

# 응답 생성 함수
def generate_response(question):
    model = "gpt-4o"
    
    response = client.chat.completions.create(
        model=model,
        temperature=0.1,
        messages=[{"role":"user", "content":question}],
    )
    
    print(response)
    answer = response.choices[0].message.content
    return answer

# 엔드포인트 정의
@app.post("/ask")
async def ask_question(request: QueryRequest):
    question = request.question
    answer = generate_response(question)
    return {"question": question, "answer": answer}

# 서버 실행
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```