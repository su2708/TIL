#TIL #스파르타코딩클럽 [[2410]]


## RNN과 기울기 폭발 문제
### 1. 기울기 폭발
- 역전파 도중, 특정 시점에서 loss의 기울기가 너무 커지는 현상
- weights 업데이트가 비정상적으로 커지고, network가 불안정해지며 학습이 망가짐


### 2. 기울기 폭발이 일어나는 이유
- RNN에서는 모든 구조가 동일한 가중치를 가짐
- 역전파 도중, 동일한 가중치가 반복해서 곱해지면서 기울기 값이 지수적으로 커질 수 있음
- 긴 시퀀스 데이터를 다룰 때 문제가 두드러짐


### 3. RNN 기울기 폭발 대책
1) 기울기 클리핑 (Gradients clipping)
	- 기울기의 절대값이 특정 임계치를 넘지 않도록 강제로 조정
	- 만약 기울기의 L2 norm이 임계치 c보다 크다면, 기울기를 아래와 같이 조정
$$
g' = g ⨉ \frac{c}{||g||_2} \qquad ( \,\, g=기울기, \,\, g'=clipping된\,\,기울기 \,\,)
$$
2) 순환신경망의 구조 변경
	- 미분값들이 소멸되거나 폭발하지 않는 새로운 경로를 둠
	- LSTM: 가중치 W와의 행렬 곱이 없는 장기 기억 경로를 추가 연결
	- GRU: LSTM의 복잡한 구조를 단순화 시킨 네트워크