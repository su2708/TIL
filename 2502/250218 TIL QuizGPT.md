#TIL [[TIL]]
## 9.4 Formatter Prompt
### Formatì„ ì§€ì •í•˜ëŠ” ì´ìœ 
- íŠ¹ì • í˜•ì‹ì„ ê°•ì œí•˜ì—¬ ì¼ê´€ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŒ
- LLMì´ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŒ
```python
questions_prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        """
        You are a helpful assistant that is role playing as a teacher.
        
        Based ONLY on the following context make 10 questions to test the user's knowledge about the text.
        
        Each question should have 4 answers, three of them must be incorrect and one should be correct.
        
        Use (o) to signal the correct answer.
        
        Question examples:
        
        Question: What is the color of the ocean?
        Answers: Red | Yellow | Green | Blue(o)
        
        Your turn!
        
        Context: {context}
        """
    )
])

questions_chain = {
    "context": format_docs
} | questions_prompt | llm

formatting_prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        """
        You are a powerful formatting algorithm.

        You format exam questions into JSON format.
        Answers with (o) are the correct ones.

        Example Input:
        Question: What is the color of the ocean?
        Answers: Red|Yellow|Green|Blue(o)

        Example Output:

        ```json
		{{
			"question": "What is the color of the ocean?",
			"answers": [
				{{
					"answer": "Red",
					"correct": false
				}},
				{{
					"answer": "Yellow",
					"correct": false
				}},
				{{
					"answer": "Green",
					"correct": false
				}},
				{{
					"answer": "Blue",
					"correct": true
				}},
			]
		}}
        ```
        Your turn!
        Questions: {context}
        """,
    )
])

formatting_chain = formatting_prompt | llm
```

### {}ì™€ {{}}ì˜ ì°¨ì´
- {}: promptì— ì–´ë–¤ ê°’ì„ ì£¼ì…í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
- {{}}: promptì—ì„œ format í•˜ì§€ ì•Šì•˜ìœ¼ë©´ í•˜ëŠ” ë¶€ë¶„ë“¤ì„ ì§€ì •í•  ë•Œ ì‚¬ìš©


---
## 9.5 Output Parser
### Output Parserì˜ ì—­í• 
1. LLM ì‘ë‹µì„ íŠ¹ì • í¬ë§·ìœ¼ë¡œ ë³€í™˜
	- LLMì€ ê¸°ë³¸ì ìœ¼ë¡œ String í˜•íƒœë¡œ ì¶œë ¥ì„ ì œê³µ
	- Stringì´ ì•„ë‹Œ JSON, Python ê°ì²´, ë¦¬ìŠ¤íŠ¸, ìˆ«ì ë“± ì›í•˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¡œ ë³€í™˜í•  ë•Œ ì‚¬ìš©

2. ì‘ë‹µì„ ì •ì œ ë° í›„ì²˜ë¦¬
	- LLMì˜ ì‘ë‹µì´ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŒ
	- Output ParserëŠ” ì´ë¥¼ ì •ë¦¬í•˜ì—¬ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰

3. ì•ˆì •ì„± í™•ë³´
	- API ì—°ë™, ë°ì´í„° ì €ì¥ ë“±ì—ì„œ ì¼ê´€ëœ í¬ë§·ì„ ë°ì´í„°ê°€ í•„ìš”í•  ë•Œ ìœ ìš©í•¨
	- LLMì´ ì˜ˆìƒì¹˜ ëª»í•œ ì¶œë ¥ì„ ë‚´ëŠ” ê²½ìš°ë¥¼ ë°©ì§€


---
## 9.8 Function Calling
### Function Calling
- GPT ëª¨ë¸ì´ í•¨ìˆ˜(ì˜ˆ: API í˜¸ì¶œ, DB ì¡°íšŒ, ê³„ì‚° ë“±)ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ê¸°ëŠ¥
- GPTê°€ ë‹¨ìˆœí•œ í…ìŠ¤íŠ¸ ì‘ë‹µì´ ì•„ë‹ˆë¼, ì™¸ë¶€ í•¨ìˆ˜ì™€ ì—°ë™í•˜ì—¬ ë”ìš± ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•¨

### Function Callingì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ 
4. ì •í™•í•œ ì‘ë‹µ ì œê³µ
	- GPTëŠ” ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì´ ìˆì§€ë§Œ, **ì •í™•í•œ ë°ì´í„°ëŠ” ë³´ì¥í•  ìˆ˜ ì—†ìŒ**
	- Function Callingì„ ì´ìš©í•˜ë©´, GPTê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ DB ì¡°íšŒ, API ìš”ì²­ì„ í•´ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒ

5. LLMì„ API ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©
	- Function Callingì„ ì‚¬ìš©í•˜ë©´ GPTê°€ ë‹¤ì–‘í•œ APIì™€ ì§ì ‘ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŒ
	- GPTê°€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ

6. ë³µì¡í•œ ì‘ì—… ìë™í™”
	- Function Callingì„ ì´ìš©í•˜ë©´ GPTê°€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜, ì—¬ëŸ¬ ê¸°ëŠ¥ì„ ì¡°í•©í•˜ì—¬ ìë™í™”ëœ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ

### Function Calling ì‚¬ìš©ë²•
7. OpenAI APIì—ì„œ Function Calling í™œì„±í™”
	- GPT ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ, `functions` íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ë©´ í•¨ìˆ˜ í˜¸ì¶œì„ í™œì„±í™” í•  ìˆ˜ ìˆìŒ

8. í•¨ìˆ˜ ì •ì˜ & OpenAIì— ë“±ë¡
	- OpenAIì—ê²Œ ì‚¬ìš©í•  í•¨ìˆ˜ì˜ **ì´ë¦„(name), ì„¤ëª…(description), ë§¤ê°œë³€ìˆ˜(parameters)** ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì „ë‹¬

```python
import openai
import json

openai.api_key = "YOUR_OPENAI_API_KEY"

# 1ï¸âƒ£ í•¨ìˆ˜ ì •ì˜ (ë‚ ì”¨ ì¡°íšŒ)
functions = [
    {
        "name": "get_weather",
        "description": "Fetches the current weather for a given city.",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {
                    "type": "string",
                    "description": "City name to get the weather for"
                }
            },
            "required": ["location"]
        }
    }
]

# 2ï¸âƒ£ ì‹¤ì œ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def get_weather(location):
    weather_data = {
        "Seoul": {"temperature": "12Â°C", "condition": "Clear"},
        "New York": {"temperature": "8Â°C", "condition": "Cloudy"},
    }
    return weather_data.get(location, {"temperature": "Unknown", "condition": "Unknown"})

# 3ï¸âƒ£ GPT ëª¨ë¸ í˜¸ì¶œ (Function Calling í™œì„±í™”)
response = openai.ChatCompletion.create(
    model="gpt-4-0613",  # Function Calling ì§€ì› ëª¨ë¸ ì‚¬ìš©
    messages=[{"role": "user", "content": "ì„œìš¸ì˜ ë‚ ì”¨ ì–´ë•Œ?"}],
    functions=functions,
    function_call="auto"  # ìë™ìœ¼ë¡œ ì ì ˆí•œ í•¨ìˆ˜ ì„ íƒ
)

# 4ï¸âƒ£ GPTê°€ í•¨ìˆ˜ í˜¸ì¶œì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸
if response["choices"][0]["message"].get("function_call"):
    function_name = response["choices"][0]["message"]["function_call"]["name"]
    function_args = json.loads(response["choices"][0]["message"]["function_call"]["arguments"])
    
    if function_name == "get_weather":
        result = get_weather(**function_args)  # ì‹¤ì œ í•¨ìˆ˜ ì‹¤í–‰
    
    print(f"ğŸŒ¦ï¸ ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨: {result['temperature']} ({result['condition']})")

```

